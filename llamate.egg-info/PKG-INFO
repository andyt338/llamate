Metadata-Version: 2.4
Name: llamate
Version: 0.1.0
Summary: A memory-augmented framework for LLMs
Author: Andy Thompson
Author-email: Andy Thompson <andyt338@gmail.com>
License: MIT
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai>=1.0.0
Requires-Dist: faiss-cpu
Requires-Dist: numpy
Requires-Dist: python-dotenv
Provides-Extra: postgres
Requires-Dist: psycopg2-binary; extra == "postgres"
Dynamic: author
Dynamic: license-file
Dynamic: requires-python

# ðŸ¦™ llamate

**llamate** is a memory-augmented agent framework for LLMs.
It adds **long-term memory** to your AI agents using OpenAI embeddings and vector search (FAISS or Postgres).

Easily plug it into your chatbot, assistant, or any language model workflow.

---

## ðŸš€ Installation

Install locally in editable mode:

```bash
pip install -e .[postgres]
```

Or install the core FAISS-only version:

```bash
pip install -e .
```

---

## ðŸ§  Quick Start (Python)

```python
from llamate import MemoryAgent

agent = MemoryAgent(user_id="andy")

# Add memory
agent.chat("Our Q4 plan is to launch Black Friday campaigns.")

# Recall memory
response = agent.chat("What did I say about Q4?")
print(response)
```

---

## ðŸ’» CLI Usage

Launch an interactive terminal session:

```bash
python -m llamate.cli --user andy
```

Example:

```bash
You: Our Q4 plan is to launch Black Friday campaigns.
LLAMate: Got it.

You: What did I say about Q4?
LLAMate: You said our Q4 plan is to launch Black Friday campaigns.
```

---

## âš™ï¸ Configuration

Create a `.env` file (or use the provided `.env.example`) in your project root:

```env
LLAMATE_OPENAI_API_KEY=sk-...
LLAMATE_VECTOR_BACKEND=faiss  # or postgres
LLAMATE_DATABASE_URL=postgresql://user:pass@localhost:5432/dbname  # if using Postgres
```

---

## ðŸ§ª Optional: Init Script

To scaffold a working `.env` file and create the Postgres table automatically:

```bash
llamate --init
```

---

## ðŸ¦ª Running Tests

```bash
pytest tests/
```

---

## ðŸ“ Project Structure

```
llamate/
â”œâ”€â”€ agent.py                 # MemoryAgent core
â”œâ”€â”€ embedder.py              # Embedding backend (OpenAI)
â”œâ”€â”€ vectorstore.py           # FAISS vector store
â”œâ”€â”€ vectorstore_postgres.py  # Postgres vector store (pgvector)
â”œâ”€â”€ backends.py              # Backend selector
â”œâ”€â”€ config.py                # Env var utilities
â”œâ”€â”€ cli.py                   # CLI interface
â”œâ”€â”€ store.py                 # Shared memory interface
â”œâ”€â”€ utils.py                 # Helpers
```

---

## âœ¨ Features

* ðŸ” OpenAI-compatible embedding backend (pluggable)
* ðŸ”Ž Vector search using FAISS or Postgres
* ðŸ§  Multi-turn, persistent memory per user
* ðŸ’¡ Easily swappable vector store backends
* ðŸ¦ª Fully tested with `pytest`
* ðŸ§  Designed for integration into existing apps or backends

---

## ðŸ“„ License

[MIT](./LICENSE) â€” Build, modify, and distribute freely.

---

## ðŸ’¡ Name origin

> Like a *llama* with *memory* ðŸ§ 
> Or a mate that remembers everything you say.
